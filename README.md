# ğŸ¤– Face-Controlled Servo with Arduino

### Let your robot â€œlookâ€ wherever you do!

---

### ğŸ‘‹ Whatâ€™s the Idea?

This project started with a fun thought:
**"What if I could make a servo motor follow my face, just like a robotic eye?"**

So, I combined two powerful worlds â€” **computer vision** and **embedded systems**. The result? A webcam tracks your face, and a servo motor connected to an Arduino turns to follow your horizontal movement in real-time.

Itâ€™s like giving your robot its first bit of *curiosity* ğŸ‘ï¸

---

### ğŸ¥ What Youâ€™ll See in the Demo:

* I move my face side to side.
* A servo motor responds instantly, mimicking that direction.
* The motor stops when my face is centered.

ğŸ‘‰ Itâ€™s smooth, responsive, and super fun to watch. *(You can find the video demo in this repo or attach it on GitHub/LinkedIn)*

---

### ğŸ§© Whatâ€™s Happening Behind the Scenes?

Hereâ€™s how the magic unfolds:

#### ğŸ§  Python + OpenCV + MediaPipe

* Captures webcam video in real-time.
* Tracks 468 facial landmarks.
* Focuses on the **nose tip** to determine horizontal face position.
* Converts that position into a servo angle (0Â°â€“180Â°).
* Sends it to Arduino via **serial communication**.

#### ğŸ¤– Arduino + Servo

* Listens for incoming angle data over the serial port.
* Rotates the servo to that exact position.

Just like that, youâ€™ve got face-to-servo motion!

---

### ğŸ› ï¸ What You Need

| Component                                        | Why Itâ€™s Needed                 |
| ------------------------------------------------ | ------------------------------- |
| Arduino board (Uno/Nano)                         | Main microcontroller            |
| SG90 Servo motor                                 | Physical motion                 |
| Jumper wires + USB                               | Connections + power             |
| Webcam                                           | Face tracking input             |
| Python (with OpenCV, MediaPipe, NumPy, pyserial) | Computer vision + communication |

---

### ğŸ—‚ï¸ File Overview

* `faceMeshModule.py` â€“ Modular class for face landmark detection using MediaPipe.
* `faceMovement.py`   â€“ Main script to capture face movement and send angles to Arduino.
* `eyeController.ino` â€“ Arduino sketch to rotate the servo based on received angles.

---

### ğŸš€ What Youâ€™ll Learn

This is more than just moving a servo. It teaches:

* Real-time **face tracking** using deep learning models.
* **Mapping physical motion** to computer vision.
* Serial communication between **Python and Arduino**.
* How hardware and software come together for interactive robotics.

---

### ğŸŒ± Room to Grow

* Add vertical tracking (tilt control).
* Use dual servos for pan & tilt.
* Smooth out jitter with angle averaging.
* Make a robotic head that reacts to people in the room!

---

### â¤ï¸ Why I Loved This

Thereâ€™s something magical about building something that reacts to *you*.
Not just sensors or switches, but your presence, your face.

Itâ€™s a beautiful intersection of **creativity**, **engineering**, and a little bit of **science fiction**.

